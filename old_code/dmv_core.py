# -*- coding: utf-8 -*-
"""DMV_core.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hD5O3t66MQbB5ig6Mbak1C1cwe7jgczj

# Extract Base Data
"""

# pip install mysql-connector-python

# @title LIBRARY
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import mysql.connector
warnings.filterwarnings('ignore')

import time
start_time = time.time()

# prompt: con querrry FE_RATIOS_SIGNALS as  ratios_bin and FE_OSCILLATORS_SIGNALS as df_oscillator_bin FE_MOMENTUM_SIGNALS as df_momentum same for FE_METRICS_SIGNAL andFE_TVV_SIGNALS...query = "SELECT * FROM crypto_listings_latest_1000"

# Establishing the connection
con = mysql.connector.connect(
    host="dbcp.cry66wamma47.ap-south-1.rds.amazonaws.com",
    port=3306,
    user="yogass09",
    password="jaimaakamakhya",
    database="dbcp"
)


query_ratios = "SELECT * FROM FE_RATIOS_SIGNALS"
ratios_bin = pd.read_sql_query(query_ratios, con)

query_oscillator = "SELECT * FROM FE_OSCILLATORS_SIGNALS"
df_oscillator_bin = pd.read_sql_query(query_oscillator, con)

query_momentum = "SELECT * FROM FE_MOMENTUM_SIGNALS"
df_momentum = pd.read_sql_query(query_momentum, con)

query_metrics = "SELECT * FROM FE_METRICS_SIGNAL"
metrics_signal = pd.read_sql_query(query_metrics, con)

query_tvv = "SELECT * FROM FE_TVV_SIGNALS"
tvv_signals = pd.read_sql_query(query_tvv, con)

# @title SQLalchemy to push data to aws db (mysql)

from sqlalchemy import create_engine

# Create a SQLAlchemy engine to connect to the MySQL database
engine = create_engine('mysql+mysqlconnector://yogass09:jaimaakamakhya@dbcp.cry66wamma47.ap-south-1.rds.amazonaws.com:3306/dbcp')



"""# DMV DATA PREP"""



import pandas as pd

# List of DataFrames to join
dfs_to_join = [ratios_bin, df_oscillator_bin, df_momentum, tvv_signals, metrics_signal]

# Perform the join, handling duplicate column names
DMV = dfs_to_join[0]
for df in dfs_to_join[1:]:
    # Get overlapping columns
    overlapping_cols = DMV.columns.intersection(df.columns).difference(['slug'])
    # Drop overlapping columns from the right DataFrame (except 'slug')
    df = df.drop(overlapping_cols, axis=1)
    DMV = pd.merge(DMV, df, on='slug', how='outer')

metrics_signal.info()

tvv_signals.info()

df_momentum.info()

df_oscillator_bin.info()

ratios_bin.info()

metrics_signal.info()

# prompt: in dmv can we sort the coloumn names using alphabetical order ... id slug name timestamp should be first 4 then you can sort

import pandas as pd
# Extract the first four columns
first_four_cols = DMV[['id', 'slug', 'name', 'timestamp']]

# Remaining columns
remaining_cols = DMV.drop(['id', 'slug', 'name', 'timestamp'], axis=1)

# Sort the remaining columns alphabetically
remaining_cols_sorted = remaining_cols.sort_index(axis=1)

# Concatenate the DataFrames back together
DMV_sorted = pd.concat([first_four_cols, remaining_cols_sorted], axis=1)

DMV_sorted.info()

## bullish and bearish counts


df=DMV_sorted
# Create new columns 'bullish', 'bearish', and 'neutral' initialized to 0
df['bullish'] = 0
df['bearish'] = 0
df['neutral'] = 0

# Iterate through rows and columns (excluding first four columns: 'id', 'slug', 'name', 'timestamp')
for index, row in df.iloc[:, 4:].iterrows():  # Start from the 5th column (index 4)
    for col_name, value in row.items():
        if value == 1:
            df.loc[index, 'bullish'] += value
        elif value == -1:
            df.loc[index, 'bearish'] += value
        elif value == 0:
            df.loc[index, 'neutral'] += value
            
DMV_sorted=df

DMV_sorted.head()

# @title SQLalchemy to push (DMV_ALL) data to aws db (mysql)

# Create a SQLAlchemy engine to connect to the MySQL database
#engine = create_engine('mysql+mysqlconnector://yogass09:jaimaakamakhya@dbcp.cry66wamma47.ap-south-1.rds.amazonaws.com:3306/dbcp')

# Write the DataFrame to a new table in the database
DMV_sorted.to_sql('FE_DMV_ALL', con=engine, if_exists='replace', index=False)

print("dmv_scores DataFrame uploaded to AWS MySQL database successfully!")

# prompt: DMV_sorted in this df .. help me create 3 new dfs .. Druability , momentum and valuation... all cols start with d go in Durability and so on .. we also need slug in every df

# Durability DataFrame
Durability = DMV_sorted[['slug'] + [col for col in DMV_sorted.columns if col.startswith('d_')]]

# Momentum DataFrame
Momentum = DMV_sorted[['slug'] + [col for col in DMV_sorted.columns if col.startswith('m_')]]

# Valuation DataFrame
Valuation = DMV_sorted[['slug'] + [col for col in DMV_sorted.columns if col.startswith('v_')]]

# prompt: Durability... what we will do is count the no of cols except for slug and then sum all values in them ... now we will take what is the sum as percentage of total no of cols .. tahat way we will have a durability score for each row ... do the same for momentum and valuation

# Durability
Durability['Durability_Score'] = (Durability.drop('slug', axis=1).sum(axis=1) / (Durability.shape[1] - 1)) * 100

# Momentum
Momentum['Momentum_Score'] = (Momentum.drop('slug', axis=1).sum(axis=1) / (Momentum.shape[1] - 1)) * 100

# Valuation
Valuation['Valuation_Score'] = (Valuation.drop('slug', axis=1).sum(axis=1) / (Valuation.shape[1] - 1)) * 100

# prompt: Durability_Score, Momentum_Score,Valuation_Score... can we make sure that keep these colums in a new df called dmv_scrores

import pandas as pd
# Create a new DataFrame with 'slug' and the score columns
dmv_scores = pd.DataFrame({
    'slug': Durability['slug'],
    'Durability_Score': Durability['Durability_Score'],
    'Momentum_Score': Momentum['Momentum_Score'],
    'Valuation_Score': Valuation['Valuation_Score']
})

dmv_scores.head(2)

# @title SQLalchemy to push (DMV_SCORES) data to aws db (mysql)

# Create a SQLAlchemy engine to connect to the MySQL database
#engine = create_engine('mysql+mysqlconnector://yogass09:jaimaakamakhya@dbcp.cry66wamma47.ap-south-1.rds.amazonaws.com:3306/dbcp')

# Write the DataFrame to a new table in the database
dmv_scores.to_sql('FE_DMV_SCORES', con=engine, if_exists='replace', index=False)

print("dmv_scores DataFrame uploaded to AWS MySQL database successfully!")

end_time = time.time()
elapsed_time_seconds = end_time - start_time
elapsed_time_minutes = elapsed_time_seconds / 60

print(f"Cell execution time: {elapsed_time_minutes:.2f} minutes")

engine.dispose()
con.close()
